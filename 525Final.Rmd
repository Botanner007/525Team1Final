---
title: "525Final"
author: "Team 1 - Jillian Chapman, Amanda Hall, Tariq Mansaray, Jennifer Snyder, David Tannerr"
date: "10/8/2019"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



##PROBLEM 3

In the Credit data in the ISLR package it contains 400 customers and information on their credit history. For full information of the data look at the help file. A company has approached us to better understand factors that influence the Balance variable which is average credit card balance in USD. Using the information in the model discuss the influential factors, and discuss the factors you choose to put in the model. Do you have any concerns about the use of certain variables in the model? Discuss how your model was created and any insights you can provide based on the results. HINT: Adding Gender and/or Ethnicity could be controversial or illegal in some uses of this this model you should discuss your decision on these variables and how it effects the organizations ability to use your model for prediction or inference.

To better understand factors that influence the average credit card balance variable ("Balance") we will explore various modeling methods and determine which variables provide us with the most useful inferences about the dataset. By determining variables to include and exclude in our analysis we will be able to provide the customer with some valuable insights for their business.

To begin, we evaluate our dataframe information.

```{r}
library(dplyr)
library(ISLR)
library(alr4)
str(Credit)
head(Credit)
summary(Credit)
```

Our dataset (Credit) is a subset of data derived from a simulated dataset containing information on ten thousand customers.  The subset contains 400 observations on 12 variables.  The summary shows that Balance could contain a zero value for some observations. The dataset does not contain N/As or negative values in any of the variables. Credit providers would not be primarily interested in 0-balance customers, but instead would seek insights pertaining to customers that carry a balance on their account. In order to identify the significant relationships between Balance and the predictors, we will omit any observations that include 0 in the Balance variable. This subset of the Credit dataset, called Credit2, will be used for fitting models with a variety of methods, in order to determine the best fit, and draw some conclusions for the customer. 

Problem Statement - What variables influence the Balance amount a customer retains? 

We first attempt to fit a model with no transformation of the variables, including zeros, to depict the influence of those 0s on the model.

```{r}
CreditM1<-lm(Balance~., data=Credit)
summary(CreditM1)
par(mfrow=c(2,2))
plot(CreditM1)
anova(CreditM1)
```
While variance is fairly consistent, we can clearly see the Balnace=0 values skewing the plots. We will test some transformations to the Balance to see if a better model fit can be reached while including all of the observations (including Balance=0).


```{r}
CreditM2<-lm(sqrt(Balance)~., data=Credit)
summary(CreditM2)
par(mfrow=c(2,2))
plot(CreditM2)
anova(CreditM2)

CreditM4<-lm(Balance^2~., data=Credit)
summary(CreditM4)
par(mfrow=c(2,2))
plot(CreditM4)
anova(CreditM4)
```
The plots after transformations are still effected by the presence of 0's in the Credit data. For the purpose of this analysis, omitting 0's will allow for the most effective conclusions and will allow models to provide clearer insight into the varibale relationships. We will continue to seek a well-fit model using a filter to exclude 0's and naming the subset Credit2. 

```{r}
Credit2=Credit%>% filter(Balance>0)
summary(Credit2)
plot(Credit2)
```

Our initial models will contain all variables present in the subset Credit2 as predictors, except Balance, which will be the response variable. In order to find the best fit, we will use multiple transfromations and fit multiple models. 


```{r}
CR2Mod1<-lm(log(Balance)~., data=Credit2)
summary(CR2Mod1)
par(mfrow=c(2,2))
plot(CR2Mod1)
anova(CR2Mod1)

CR2Mod2<-lm(sqrt(Balance)~., data=Credit2)
summary(CR2Mod2)
par(mfrow=c(2,2))
plot(CR2Mod2)
anova(CR2Mod2)

CR2Mod3<-lm(Balance^2~., data=Credit2)
summary(CR2Mod3)
par(mfrow=c(2,2))
plot(CR2Mod3)
anova(CR2Mod3)

CR2Mod4<-lm(Balance~., data=Credit2)
summary(CR2Mod4)
par(mfrow=c(2,2))
plot(CR2Mod4)
anova(CR2Mod4)
```
The Plots for CR2Mod1 seem to fit best while CR2Mod4 has the highest R-squared value which means it appears to be most significant, but R-squared values shouldn't soley decide on the fit of a model. We will continue with the log transformation since it seems to show the best fit for the model. Next, we will eliminate any insignificant variable to create a simpler model, and then explore if any interactions would help our model.

---- replacement text
CR2Mod4 has the highest R-squared value which means we can account for 99.94% of _________, but R-squared values shouldn't soley decide the fit of a model. If we review the plots generated, CR2Mod4 also appears to look most like we want to see.  In light of this information, we will continue with CR2Mod4 and eliminate any insignificant variables to create a simpler model.  Afterwards, we'll explore the effect of interactions in the hope that they would improve our model even more.
---- 

From the Credit2 subset's summary we can see that all the variables are significant at the 0.05 level except: ID, Education, Gender, Married and Ethnicity.  We will remove these variables and rerun our summary data.

```{r}
CR2Mod5<-lm(Balance~Income+Limit+Rating+Cards+Age+Student, data=Credit2)
summary(CR2Mod5)
par(mfrow=c(2,2))
plot(CR2Mod5)
anova(CR2Mod5)
anova(CR2Mod5,CR2Mod4)
```

Our ANOVA comparing CR2Mod4 (the bigger model) and CR2Mod5 (the smaller model) shows a p-value of greater than 0.05.  Due to this, we would reject the notion that the models are different and choose the simplier model to work with.  The review of our plots confirm the similarity of the the models.  To be sure the CR2Mod5 is exactly what we need, we'll run a ncvTest, boxCox and powerTransformation.

```{r}
ncvTest(CR2Mod5)
boxCox(CR2Mod5)
attach(Credit2)
summary(powerTransform(cbind(Balance,Income,Limit,Rating,Cards,Age,Student)))
detach(Credit2)
```

The ncvTest's p-value shows non-signficance; thus, constant variance is present.  The boxCox proves curious as there is no confidence level shown other than at 1 and the curve is not the typical arc expected. When we compare it to the powerTranform the likelihood ratios both show at significant level, confirming transforming to log or not transforming at all is not the same as using the recommended transformation provided.  The recommended transformation for all variables except the Student factor, appears to be to the power of 1.  Since increasing a variable to the power of one would simply be it's own number, we will opt to not transform the variables.  An move to add interactions in the hope that they will improve our model.

```{r}
CR2Mod6<-lm(Balance~Income+Limit+Rating+Cards+Age+Student+Income*Limit+Rating*Limit, data=Credit2)
summary(CR2Mod6)
par(mfrow=c(2,2))
plot(CR2Mod6)
anova(CR2Mod6)
anova(CR2Mod5,CR2Mod6)
```


To start to show you these processes from a computational point of view let's look at a example where we know how the true data was generated.
We will generate a model with 5 predictor variables, that are generated from a normal distribution, and have no correlation between the predictors.  Out of the 5 variables only variable 2 and 4 
are used in the model
```{r cahce=TRUE}
library(mvtnorm)
set.seed(2016)
X=rmvnorm(100,rep(0,5))
Y=2+4*X[,2]+3*X[,4]+rnorm(100,0,1.5)

Mod=lm(Y~X[,1]+X[,3]+X[,2]+X[,4]+X[,5])
summary(Mod)
```


First we will use the `drop1` function to show backward elimination one step from the full model presented above.  
```{r cahce=TRUE}
drop1(Mod)
```
Notice this calculates the AIC and RSS associated with each variable.  The variable removed is presented in the far left column it compares the 6 possible models, removing each variable, and then sticking with the full model. 


Now let's do the full backward selection and see what the model looks like, by default R uses AIC.  
```{r cache=TRUE}
M=step(Mod,direction="backward")
```

R gives the trace of the function, the decision made at each step.  As we can see it removes variable 3 first, then it removes variable 1, and finally stops after removing variable 5.  

Now if we use BIC we would just do (reminder 100 is the sample size),

```{r cache=TRUE}
M=step(Mod,direction="backward", k=log(100))
```

We see that it agrees with the same steps as the AIC model presented.


If we want to do forward selection, we need to define the scope the model, that means the smallest and largest models that you will consider.  Forward selection will start at the first model you give it. Notice how we use the `~1` which indicates the smallest model we consider is the intercept only model.  We define `M0` to be the intercept only model, and then the lower and upper to define
the possible sets and combinations.  

```{r cahce=TRUE}
M0=lm(Y~1)
M2=step(M0,scope=list(lower=~1, upper=~X[,1]+X[,2]+X[,3]+X[,4]+X[,5]),direction="forward")
```
Notice it only takes two steps, adding variable 2 and then variable 4. 


If we don't specify a direction it uses stepwise regression (the combo of forward and backward).

```{r cache=TRUE}
M0=lm(Y~1)
M3=step(M0,scope=list(lower=~1, upper=~X[,1]+X[,2]+X[,3]+X[,4]+X[,5]))
```
Take a look at the first column, if it has a `+` before a variable it corresponds to adding a that variable if it has a `-` corresponds to subtracting that variable.  

All models we have seen agree, on the model that corresponds to how the data is generated, but there is no guarantee that all methods will agree, which means you should think through 
how you are going to do the model selection.



```{r}
Credit2_Mean<- mean(Credit2$Student)

set.seed(1000)
Mine <- Sys.time()
boots <- NULL
for (i in 1:1000){
  Credit2_Mean <- mean(sample(Credit2$Balance, 777, replace = TRUE))
  boots <- c(boots, Credit2_Mean)}  

Mine2 <- Sys.time()
Mine2-Mine

hist(boots, main= "Sample Distribution of Balance Means")


```

Now, I will calculate a confidence interval of 80%.

```{r}
quantile(boots,c(.1,.9))
hist(boots)
abline(v=quantile(boots,c(.1,.9)),col=2)
```
This output details that 10% of the bootstrap means are below 652.3360 , and 10% are above 690.8533  Therefore, we are 80% confident based on this bootstrap confidence interval that the mean of balances recieved is between 652.3360 and 690.8533.


### Problem 4


For this problem we used the Salaries data in the carData package to investigate the gender gap in the data. Our data represents the salaries of professors in the 2008-2009 year in an unspecified college. The data set consists of 397 observations with 6 variables each. The variables we will be looking at are "rank", "discipline", "yrs.since.PhD" or years since PhD, "yrs.service" or years of service, "sex", and finally "salary" as our response variable.

We looked at the help file and summary of the Salaries data to see exactly what we aer working with. 
```{r}
library(carData)
data("Salaries")
summary(Salaries)
```
Next, we plotted the data and viewed unique elements. 
```{r}
plot(Salaries)
str(Salaries)

```
We can see the data and the type of variables we are working with in the data. Each variable set seems to be correlated all over the place. Several have strage plots due to them being factor variables. 

```{r}
unique(Salaries$rank)
unique(Salaries$discipline)
unique(Salaries$sex)
```
We can also see the levels of each factors we are working with. 

Next, we want to see how many females are in each rank, and if this could play in role in salary difference between males and females for us to investigate further.
```{r}
summary(Salaries$rank)
table(Salaries$sex,Salaries$rank)
```
We can see that Female is pretty evenly distributed between the three ranks; however, Male is equally distirbuted between Assistant and Assocaite but is very heavily weighted in Full Professoor compared to the other two ranks. This could be because Male professors have more years of service than females, and therefore, males have had more time/opportunity to receive promotion. 

Next, we will look at the years of service for Male and Female to see if that can explain the heavier weight of Full Professors that are males. 
```{r}
table(Salaries$sex,Salaries$yrs.service)
```
We can see that there is only one female with more than 27 years of experience, with the majority of them below 20 years of expereince. 

Next, we are going to look at the preliminary difference in means.
```{r}
sexmeans <- tapply(Salaries$salary, Salaries$sex, mean)

sexmeans[2]-sexmeans[1]
```


Let's run a t-test now between the difference in means.
We ran a t-test to test that null hypothesis that the mean salary of males in this population is less than or equal to the mean salary of females, and the alternative hypothesis that the mean salary of males in this population is greater than the mean salary of females.
```{r}
t.test(x=Salaries$salary[Salaries$sex=="Male"], y=Salaries$salary[Salaries$sex=="Female"], alternative="greater")
isalariesfit <- lm(salary ~., data=Salaries)
```
Looking at the t-test, it looks like we are not able to accept the null at any significance level. We will go further and create models to help explain the salary data. 

We created a model to see what variables affect salary, with salary as the response variable and the remaining variables as the predictors. 
```{r}
salariesfit <- lm(salary ~., data=Salaries)
summary(salariesfit)
```
We can see that the intercept is 65955, which is the baseline salary in USD for a female, assistant professor with a discipline of 'a'. ## Ph.D??##
I can see that all other variables held constant that the sex of Male would increase that baseline salary by 4783; however, looking at the p-value of 0.215, indicates it is not significant at the 0.05 or 0.01 level. Also, yrs.since.phd and yrs.service are not significant at the 0.01 level. Also, I can see how salary increases when faculty members get promoted to an Associate professor and to a Full professor.

Next, we used an ANOVA to compare the significance of each variable using their variance.
```{r}
anova(salariesfit)
```
The anova tells us that years since phd and sex seem to be variables that do not matter in this model based on their p-values. It could possibly be due to the fact that we only have data for 39 female professors, and 358 male professors. In general, we may not have enough data to show if there is truly a gender gap in pay. The more important question is is there a gender gap in hire from what our descriptive data tells us? Let's check for assumptions.

We plotted the model to check for non-constant, variance, normaility and outliers in the data, and we used ncvTest 
```{r}
par(mfrow=c(2,2))
plot(salariesfit)
```

```{r}
ncvTest(salariesfit)
```
We can see that normalization of residuals and the non constant variance assumptions have been violated. It is a possibility of a curvature in our model as well. Let's try transforming our response variable using the box-cox method.

We looked at the boxCox to see how and if we should transform the repsponse variable.
```{r}
boxCox(salariesfit)
```
Our lambda is -1, meaning to transform our resposne variable with a power of -1. 

Then, we took the inverse of our response variable. 

```{r}
salariesassump <- lm(salary^(-1)~rank+discipline+yrs.since.phd+yrs.service+sex, data=Salaries)
summary(salariesassump)
```
We can see that years since phd still seems to be insignificant at any level, and the adjustment for male is not significant when we test at a 5% significance level

```{r}
par(mfrow=c(2,2))
plot(salariesassump)
ncvTest(salariesassump)
```
As far as our assumptions, they are better than the previous model before our transformation. 

Next, we took a full transformation of all our variables.
```{r}
summary(powerTransform(cbind(salary, rank, discipline, yrs.since.phd, yrs.service, sex) ~1, Salaries, family="bcnPower"))
```
The lambda values suggest us to transform the variables "rank" and "sex", which are factor variables; however, using the power of a factor has absolutely no interpretability. The suggestion of putting yrs.since.phd and yrs.service also suggest to use the power of 0.5, which is the same as taking the square root of those variables. Interpretation may become an issue with the latter variables as well. 

```{r}
salariesassump2 <- lm(salary^(-1)~rank+discipline+I(yrs.since.phd^(0.5))+I(yrs.service^(0.5))+sex, data=Salaries)
summary(salariesassump2)

```
```{r}
par(mfrow=c(2,2))
plot(salariesassump2)
ncvTest(salariesassump2)
```

The assumptions are "more" met compared to the original model, but it seems as if the non constant variance is slightly worse compared to the second model. Also, the interpretability of using the power of 0.5, or the square root of predictor variables is very hard and hazy. 

Due to these factors, we decided to utilize the second model, where we only transformed the response variable. 

```{r}
anova(salariesassump)
```

Years since pHD is once again a variable that doesn't seem to matter in our model. Sex may be a usless variable as well if we test it against a significance of 5%. 

To fully test the best model we can use, we are finally going to implement stepwise selection using backwards, forwards, and the stepwise methods.
```{r}
mod <- step(salariesassump, scope=list(lower=~1, upper=~rank+discipline+yrs.since.phd+yrs.service+sex), data=Salaries)
```
The stepwise method says using all variables except yrs.since.phd is acceptable. 

Next, we used the backwards method. 
```{r}
mod2 <- step(salariesassump, scope=list(lower=~1, upper=~rank+discipline+yrs.since.phd+yrs.service+sex), direction="backward", data=Salaries)
```
The backwards method agrees to only remove yrs.since.phd. 

Finally, we used the forward method. 
```{r}
salariesintc. <- lm(salary^(-1)~1, data=Salaries)
mod3 <- step(salariesintc., scope=list(lower=~1, upper=~rank+discipline+yrs.since.phd+yrs.service+sex), direction="forward", data=Salaries)

```
All models seem to agree that the only variable that we shold remove is yrs.since.phD. 

We looked at the summary table of our linear regression model after the transformation of our response variable. 
```{r}
salariesassump3 <- lm(salary^(-1)~rank+discipline+yrs.service+sex, data=Salaries)
summary(salariesassump3)
```

Now to interpret what our data is trying to tell us..........


From our data, we see that sex is an important variable, but it is difficult to identify if there is a gender gap between Male and Female. Looking at the summary table of our linear regression model after the transformation, the adjustment from female to male seems to not play significant role when we are testing at a 5% significance level; however, at a 10% level, there is a difference in pay between genders, which indicates males make slightly less when we adjust from female to male. However, our original t-test tells us that there is a gender gap in pay. There may be a discrimination in pay when it comes to gender, but with more males in our data than females in the data set that was presented to us, it is very hard to identify. 















