---
title: "525Final"
author: "Team 1 - Jillian Chapman, Amanda Hall, Tariq Mansaray, Jennifer Snyder, David Tanner"
date: "10/8/2019"
output: word_document
---


```{r,include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
## PROBLEM 1

Bootstrapping is the process of using a single collected sample, assuming it represents the population as a whole, and analyzing the sampling distribution of the resampled data. You use bootstrapping to create a distribution from your data when you do not know how to apply the central limit theorem. Bootstrapping depends on the sample being used and it’s randomness. If both are appropriate, a distribution created via the bootstrapping method will be a sound representation of the population distribution and analysts may provide inference about the population based on its conclusions.  However, if the utilized sample is poor then bootstrap inference will be poor or misleading. A goal of bootstrapping is to create a confidence interval for reasonable values of θ. Bootstrap tests are not exact and are very dependent on the sample data representing population because they do not consider other assumptions like equality of variance. By bootstrapping, we are able to quantify the uncertainty of our model.
To begin the bootstrapping process, you resample n data points with replacement from the original dataset. When using the bootstrap method, the resampling with replacement is repeated k times until you have k bootstrap statistics. Those statistics are then plotted and depicted as a distribution. The distribution output of the plot depiction of the bootstraps is described by calculating confidence intervals in two possible approaches.  The first approach is to take the sampling distribution that was created and pull the quantiles. The second approach is to create a confidence interval using the point estimate by utilizing the bootstrap standard error and the standard deviation of the bootstrap sampling distribution. We know that, “If the interval is bell shaped, both will produce similar results, if it’s not bell shaped (normal) we know we should use the quantiles rather than the standard formulation.” Bootstrapping a good method when your sample size is less than desired, and it is effective in estimating population parameters and providing insight to the population from which the data came.
In randomized distribution, a sampling distribution is created to define and test your hypothesis through generated test statistics. Randomization is a statistical significance test that creates a sampling distribution under the null hypothesis by resampling without replacement.  First, you define your null and alternative hypotheses, then sample without replacement under the null hypothesis and generate the distribution. This is done by calculating the difference of the two means, to determine the sample statistic, saving that calculation, and repeating to create a distribution. Last, you determine if the data falls within the resampled distribution. 
While both bootstrapping and randomization are methods used to create sample distributions, the randomization method refers to that distribution as the “null distribution”. Resampling with replacement is a characteristic of bootstrapping, while randomization contrasts by resampling without replacement. In simulating the null distribution through randomization, we create a depiction to which we can compare the original data. The bootstrapping method tests hypotheses regarding parameters while the randomization method tests hypotheses concerning distribution of resampled data. Therefore, randomization allows for slightly more flexibility in assumptions than bootstrapping. The same dataset could be analyzed with the randomization method, as with the bootstrap method, but, instead of drawing samples with replacement, randomization systematically or randomly reorders the data (more like just shuffling it) a designated amount of times, and then calculates test statistics on each reordering. Randomized distributions are the hypothesis test version of bootstrapping and require the analyst to define hypotheses. 
http://statweb.stanford.edu/~susan/courses/b494/node3.html#SECTION00330000000000000000
http://www.ievbras.ru/ecostat/Kiril/R/Biblio_N/R_Eng/Zieffler2011.pdf
Randomization (Video: Module1Page31 - Comparing marketing strategies)

## PROBLEM 2


## PROBLEM 3

_In the Credit data in the ISLR package it contains 400 customers and information on their credit history. For full information of the data look at the help file. A company has approached us to better understand factors that influence the Balance variable which is average credit card balance in USD. Using the information in the model discuss the influential factors, and discuss the factors you choose to put in the model. Do you have any concerns about the use of certain variables in the model? Discuss how your model was created and any insights you can provide based on the results. HINT: Adding Gender and/or Ethnicity could be controversial or illegal in some uses of this this model you should discuss your decision on these variables and how it effects the organizations ability to use your model for prediction or inference_

To better understand the factors that influence the average credit card balance, we will explore various modeling methods and determine which variables provide us with the most useful information. By examining multiple variables in our analysis, we should be able to provide our customer with some valuable insights for their business.

```{r,include=FALSE}
library(dplyr)
library(ISLR)
library(alr4)
str(Credit)
head(Credit)
```

We begin by evaluating our dataframe information. Our data, Credit, is derived from a simulated dataset containing information on 400 observations of 12 variables. The summary shows that Balance could contain a zero value for some observations, but no other variables contain zeros, N/As or negative values.  

```{r,include=TRUE}
summary(Credit)
```

Since credit providers would primarily be interested in seeking insights pertaining to customers that carry a balance on their accounts, we will omit any observations that include zeros in the Balance variable. This new subset of the Credit data, called Credit2, will be used for fitting our models via a variety of methods, in order to determine the best fit and draw conclusions for our customer.

Problem Statement - What variables influence the Balance amount a customer retains? 

To confirm our thoughts about the need to subset Credit, we first attempt to fit a model with no transformation of any of the variables, including the zeros, using the Credit dataset to depict the influence of those zeros on the model.

```{r,include=FALSE}
CreditM1<-lm(Balance~., data=Credit)
summary(CreditM1)
anova(CreditM1)
```

```{r,include=TRUE}
par(mfrow=c(2,2))
plot(CreditM1)
```

While the variance shown in the plot is fairly consistent, we can clearly see the Balnace=0 values skewing the data. We’ll test some basic transformations (sqrt and ^2, but no log because of the zeros) on the Balance to see if a better model fit can be obtained while retaining all of the observations (including Balance=0).

```{r,include=FALSE}
CreditM2<-lm(sqrt(Balance)~., data=Credit)
summary(CreditM2)
anova(CreditM2)

CreditM3<-lm(Balance^2~., data=Credit)
summary(CreditM3)
anova(CreditM3)
```

__sqrt:__

```{r,include=TRUE}
par(mfrow=c(2,2))
plot(CreditM2)
```

__^2:__

```{r,include=TRUE}
par(mfrow=c(2,2))
plot(CreditM3)
```

The plots, shown after the transformations, are clearly still effected by the presence of the zeros. Thus, for the purpose of our analysis, omitting the zeros will allow for the most effective conclusions and will permit our models to provide clearer insight into the varibale relationships. We will continue to seek a well-fit model using the aforementioned filter and generate a subset, Credit2, which excludes the zeros. 

```{r,include=FALSE}
Credit2=Credit%>% filter(Balance>0)
plot(Credit2)
```

```{r,include=TRUE}
summary(Credit2)
```

The summary data shows the zeros in Balance have been removed; now we can attempt to fit better models from this subset.  All of the variables, except Balance, will be used as predictors, and Balance will continue to be our response variable. To find the best fit, we will begin by using multiple transformations of Balance, including log, sqrt, ^2 and no transformation. 


```{r,include=FALSE}
CR2Mod1<-lm(log(Balance)~., data=Credit2)
anova(CR2Mod1)
summary(CR2Mod1)
CR2Mod2<-lm(sqrt(Balance)~., data=Credit2)
anova(CR2Mod2)
summary(CR2Mod2)
CR2Mod3<-lm(Balance^2~., data=Credit2)
anova(CR2Mod3)
summary(CR2Mod3)
CR2Mod4<-lm(Balance~., data=Credit2)
anova(CR2Mod4)
summary(CR2Mod4)
```

__log__
Multiple R-squared:  0.7836,	Adjusted R-squared:  0.7749  

```{r,include=TRUE}
par(mfrow=c(2,2))
plot(CR2Mod1)
```

__sqrt__
Multiple R-squared:  0.9591,	Adjusted R-squared:  0.9575

```{r,include=TRUE}
par(mfrow=c(2,2))
plot(CR2Mod2)
```

__^2__
Multiple R-squared:  0.9201,	Adjusted R-squared:  0.9168 

```{r,include=TRUE}
par(mfrow=c(2,2))
plot(CR2Mod3)
```

__None__
Multiple R-squared:  0.9994,	Adjusted R-squared:  0.9994 
```{r,include=TRUE}
par(mfrow=c(2,2))
plot(CR2Mod4)
```


The model with no transformation to Balance has the highest R-squared value which means we can account for 99.94% of the variance with this model, but R-squared values shouldn't soley decide the fit of a model. If we review the plots generated, the no transformation plot also appears to look most like we want to see.  In light of these results, we will continue without transforming Balance and move forward with eliminating any insignificant variables in an effort to create a simpler model.  An anova should help with this, but first we'll review the model's summary.

```{r,include=TRUE}
summary(CR2Mod4)
```

In this summary of the model without transformations, we see that all the variables were significant at the 0.05 level except: ID, Education, Gender, Married and Ethnicity.  We will remove these variables, rerun our summary data, take a look at the plot and compare the original model with our simplified model.

```{r,include=FALSE}
CR2Mod5<-lm(Balance~Income+Limit+Rating+Cards+Age+Student, data=Credit2)
```


```{r,include=TRUE}
summary(CR2Mod5)
par(mfrow=c(2,2))
plot(CR2Mod5)
```

So far, this looks promising.  Our plots confirm the similarity of the the models. 

```{r,include=TRUE}
anova(CR2Mod5)
anova(CR2Mod5,CR2Mod4)
```

The ANOVA comparing our no transformation-all inclusive (bigger) model and our smaller simplified model shows a p-value of greater than 0.05.  Due to this, we would accept the notion that the models are the same and choose the simplier model to work with.  To be sure the simplified model is all that we need, we'll run a ncvTest, boxCox and powerTransformation.

```{r,include=TRUE}
ncvTest(CR2Mod5)
```

The ncvTest's p-value shows non-signficance; thus, constant variance is present. 

```{r,include=TRUE}
boxCox(CR2Mod5)
```

The boxCox proves curious as there is no confidence level shown other than at 1 and the curve is not the typical arc expected.

```{r,include=TRUE}
attach(Credit2)
summary(powerTransform(cbind(Balance,Income,Limit,Rating,Cards,Age,Student)))
detach(Credit2)
```

When we look to the powerTranform, the likelihood ratios both show at a significant level, confirming transforming to log or not transforming at all is not the same as using the recommended transformation provided.  The recommended transformation for all variables except the Student factor, appears to be to the power of 1.  Since increasing a variable to the power of one would simply be it's own number, we will opt to - again - not transform the variables, and move to add interactions in the hope that they will improve our model.

Since one would expect retaining a balance on a credit would be associated with the ability to pay the balance off (Income) or a focus on increasing a credit score (Rating), these are the two interactions we'll attempt in our model.  


```{r,include=FALSE}
CR2Mod6<-lm(Balance~Income+Limit+Rating+Cards+Age+Student+Income*Limit+Rating*Limit, data=Credit2)
```

A review of the model's summary proves interesting.  While the interaction of Rating to Limit shows significant at the  level, Income to Limit does not.  Also, including these interactions causes Rating to shift above the signifiance level.  We'll continue to evaluate this new model by looking at the plots.

```{r,include=TRUE}
summary(CR2Mod6)
```

Nothing appears out of the ordinary with the following plots.  We'll review the anovas for additional information.

```{r,include=TRUE}
par(mfrow=c(2,2))
plot(CR2Mod6)
```

The one-way anova of our model with interactions confirms the interaction of Income to Limit is insignificant.

```{r,include=TRUE}
anova(CR2Mod6)
```

Our final evaluation of the interaction model shows a p-value of 0.05854.  A value so close to the border of significance we wonder if the interactions have really added any additional information for our client when trying to infer why a balance would be retained.  Thus, we will abandon this line of evaluation and shift to a stepwise model selection for additional insight.

```{r,include=TRUE}
anova(CR2Mod5,CR2Mod6)
```

We initiate the stepwise model selection with a backwards option as this process has the aiblity to evalute the greatest amount of information we have available to us and uses the most predictors.

```{r,include=FALSE}
CR2Mod7=step(CR2Mod4,direction="backward")
```

The stepwise model begins with 

__Balance ~ ID + Income + Limit + Rating + Cards + Age + Education + Gender + Student + Married + Ethnicity__
    
and iterates through until it reaches its conclusion

__Balance ~ Income + Limit + Rating + Cards + Age + Student + Married__

The backwards step matches our chosen model closely, as Married is the only variable that is discrepant.  The variables both models agreed upon were Income, Limit, Rating, Cards, Age, and Student.  These variables, as well as Married, are worth further investigation including added variable plots to evaluate relationships and additional interaction modeling.



### Problem 4


For this problem we used the Salaries data in the carData package to investigate the gender gap in the data. Our data represents the salaries of professors in the 2008-2009 year in an unspecified college. The data set consists of 397 observations with 6 variables each. The variables we will be looking at are "rank", "discipline", "yrs.since.PhD" or years since PhD, "yrs.service" or years of service, "sex", and finally "salary" as our response variable.

We looked at the help file and summary of the Salaries data to see exactly what we aer working with. 
```{r}
library(carData)
data("Salaries")
summary(Salaries)
```

Next, we plotted the data and viewed unique elements. 
```{r}
plot(Salaries)
str(Salaries)

```

We can see the data and the type of variables we are working with in the data. Each variable set seems to be correlated all over the place. Several have strage plots due to them being factor variables. 
```{r}
unique(Salaries$rank)
unique(Salaries$discipline)
unique(Salaries$sex)
```

We can also see the levels of each factors we are working with. 

Next, we want to see how many females are in each rank, and if this could play in role in salary difference between males and females for us to investigate further.
```{r}
summary(Salaries$rank)
table(Salaries$sex,Salaries$rank)
```

We can see that Female is pretty evenly distributed between the three ranks; however, Male is equally distirbuted between Assistant and Assocaite but is very heavily weighted in Full Professoor compared to the other two ranks. This could be because Male professors have more years of service than females, and therefore, males have had more time/opportunity to receive promotion. 

Next, we will look at the years of service for Male and Female to see if that can explain the heavier weight of Full Professors that are males. 
```{r}
table(Salaries$sex,Salaries$yrs.service)
```
We can see that there is only one female with more than 27 years of experience, with the majority of them below 20 years of expereince. 

Next, we are going to look at the preliminary difference in means.
```{r}
sexmeans <- tapply(Salaries$salary, Salaries$sex, mean)

sexmeans[2]-sexmeans[1]
```


Let's run a t-test now between the difference in means.
We ran a t-test to test that null hypothesis that the mean salary of males in this population is less than or equal to the mean salary of females, and the alternative hypothesis that the mean salary of males in this population is greater than the mean salary of females.
```{r}
t.test(x=Salaries$salary[Salaries$sex=="Male"], y=Salaries$salary[Salaries$sex=="Female"], alternative="greater")
isalariesfit <- lm(salary ~., data=Salaries)
```

Looking at the t-test, it looks like we are not able to accept the null at any significance level. We will go further and create models to help explain the salary data. 

We created a model to see what variables affect salary, with salary as the response variable and the remaining variables as the predictors. 
```{r}
salariesfit <- lm(salary ~., data=Salaries)
summary(salariesfit)
```
We can see that the intercept is 65955, which is the baseline salary in USD for a female, assistant professor with a discipline of 'a'.
I can see that all other variables held constant that the sex of Male would increase that baseline salary by 4783; however, looking at the p-value of 0.215, indicates it is not significant at the 0.05 or 0.01 level. Also, yrs.since.phd and yrs.service are not significant at the 0.01 level. Also, I can see how salary increases when faculty members get promoted to an Associate professor and to a Full professor.

Next, we used an ANOVA to compare the significance of each variable using their variance.
```{r}
anova(salariesfit)
```
The anova tells us that years since phd and sex seem to be variables that do not matter in this model based on their p-values. It could possibly be due to the fact that we only have data for 39 female professors, and 358 male professors. In general, we may not have enough data to show if there is truly a gender gap in pay. The more important question is is there a gender gap in hire from what our descriptive data tells us? Let's check for assumptions.

We plotted the model to check for non-constant, variance, normaility and outliers in the data, and we used ncvTest 
```{r}
par(mfrow=c(2,2))
plot(salariesfit)
```

```{r}
ncvTest(salariesfit)
```
We can see that normalization of residuals and the non constant variance assumptions have been violated. It is a possibility of a curvature in our model as well. Let's try transforming our response variable using the box-cox method.

We looked at the boxCox to see how and if we should transform the repsponse variable.
```{r}
boxCox(salariesfit)
```
Our lambda is -1, meaning to transform our resposne variable with a power of -1. 

Then, we took the inverse of our response variable. 

```{r}
salariesassump <- lm(salary^(-1)~rank+discipline+yrs.since.phd+yrs.service+sex, data=Salaries)
summary(salariesassump)
```
We can see that years since phd still seems to be insignificant at any level, and the adjustment for male is not significant when we test at a 5% significance level

```{r}
par(mfrow=c(2,2))
plot(salariesassump)
ncvTest(salariesassump)
```
As far as our assumptions, they are better than the previous model before our transformation. 

Next, we took a full transformation of all our variables.
```{r}
summary(powerTransform(cbind(salary, rank, discipline, yrs.since.phd, yrs.service, sex) ~1, Salaries, family="bcnPower"))
```
The lambda values suggest us to transform the variables "rank" and "sex", which are factor variables; however, using the power of a factor has absolutely no interpretability. The suggestion of putting yrs.since.phd and yrs.service also suggest to use the power of 0.5, which is the same as taking the square root of those variables. Interpretation may become an issue with the latter variables as well. 

```{r}
salariesassump2 <- lm(salary^(-1)~rank+discipline+I(yrs.since.phd^(0.5))+I(yrs.service^(0.5))+sex, data=Salaries)
summary(salariesassump2)

```
```{r}
par(mfrow=c(2,2))
plot(salariesassump2)
ncvTest(salariesassump2)
```

The assumptions are "more" met compared to the original model, but it seems as if the non constant variance is slightly worse compared to the second model. Also, the interpretability of using the power of 0.5, or the square root of predictor variables is very hard and hazy. 

Due to these factors, we decided to utilize the second model, where we only transformed the response variable. 

```{r}
anova(salariesassump)
```

Years since pHD is once again a variable that doesn't seem to matter in our model. Sex may be a usless variable as well if we test it against a significance of 5%. 

To fully test the best model we can use, we are finally going to implement stepwise selection using backwards, forwards, and the stepwise methods.
```{r}
mod <- step(salariesassump, scope=list(lower=~1, upper=~rank+discipline+yrs.since.phd+yrs.service+sex), data=Salaries)
```
The stepwise method says using all variables except yrs.since.phd is acceptable. 

Next, we used the backwards method. 
```{r}
mod2 <- step(salariesassump, scope=list(lower=~1, upper=~rank+discipline+yrs.since.phd+yrs.service+sex), direction="backward", data=Salaries)
```
The backwards method agrees to only remove yrs.since.phd. 

Finally, we used the forward method. 
```{r}
salariesintc. <- lm(salary^(-1)~1, data=Salaries)
mod3 <- step(salariesintc., scope=list(lower=~1, upper=~rank+discipline+yrs.since.phd+yrs.service+sex), direction="forward", data=Salaries)

```
All models seem to agree that the only variable that we shold remove is yrs.since.phD. 

We looked at the summary table of our linear regression model after the transformation of our response variable. 
```{r}
salariesassump3 <- lm(salary^(-1)~rank+discipline+yrs.service+sex, data=Salaries)
summary(salariesassump3)
```

Now to interpret the data, it looks as if the change betwen a female professor and a male is not significant, in other words the difference in salaries is negligible. Professors that are in theoretical departments seem to get paid more than those that work in applied departments. Of course, going from an assistant professor to a associate professor tends to see a jump in salary and likewise, going from associate professor to just professor sees another jump in one's salary. to put things into perspective, we can confidently say if you had came into a college as an assistant professor in a theoretical department you would more than likely have the lowest salary relatively speaking. As the years go by, your salary should also increase. Now in contrast, if you were to come into a university as a full Professor teaching in an applied department, you would likely see a higher salary. The years of service may indicate that many full professors came in with lower salaries. It is also possible that there is not any salary parity.

From our data, we see that sex is an important variable, but it is difficult to identify if there is a gender gap between Male and Female. Looking at the summary table of our linear regression model after the transformation, the adjustment from female to male seems to not play significant role when we are testing at a 5% significance level; however, at a 10% level, there is a difference in pay between genders, which indicates males make slightly less when we adjust from female to male. However, our original t-test tells us that there is a gender gap in pay. There may be a discrimination in pay when it comes to gender, but with more males in our data than females in the data set that was presented to us, it is very hard to identify. Lastly, our anova model states that sex is a useless variable wherelese our stepwise regression opted to keep it. Just as was said before, the amount of females to males may be skewing the data. 















